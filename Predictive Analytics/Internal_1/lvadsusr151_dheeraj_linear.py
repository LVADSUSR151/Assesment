# -*- coding: utf-8 -*-
"""LVADSUSR151_Dheeraj_linear.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cFnRzyjK9sRX7p-oITJGp9hLzo4eKV3k
"""

# problem 1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler

# 1 managing null

df = pd.read_csv('/content/expenses.csv')

df.head()

df.info()

df.describe()

"""minimum age is 18 and maximum age is 64 which suggest that company does not gives insurnce to the persons outside this age group."""

df.isnull().sum()

"""there are 16 missing values in bmi so i gonna fill that with mean of bmi."""

df.fillna(df['bmi'].mean(),inplace = True)

df.isnull().sum()

"""now there is no missing values"""

# 2 outliers

sns.displot(df['charges'])
plt.title('distribution of charges')

plt.boxplot(df['charges'])

"""there are some outliers in vharges colums but there may be some other reasons for company tho charge them more so i gonna keep them."""

plt.boxplot(df['age'])

sns.scatterplot(df,x='age',y='charges')

# 3 encoding

df.head()

dummies=['sex','smoker','region']
df=pd.get_dummies(df,columns=dummies,drop_first =True)

df.head()

df.shape

sns.heatmap(df.corr(),cmap='coolwarm', linewidths=0.5)

"""not droping any columns"""

plt.figure(figsize=(8, 6))
corr=df.corr()
corr.style.background_gradient(cmap="inferno")

X = df.drop(['charges'], axis=1)
y = df['charges']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = MinMaxScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
# mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print('mean_squared_error ',mse)
print('r2_score ',r2)























































































# linear
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

plt.figure(figsize=(8, 6))
sns.heatmap(df, annot=True, cmap='coolwarm', linewidths=0.5)
corr=data.corr()
corr.style.background_gradient(cmap="inferno")


encoded_df = pd.get_dummies(df['State'---------])
dummies=['purpose', 'zip_code', 'grade', 'verification_status', 'application_type', 'home_ownership']
data=pd.get_dummies(data,columns=dummies,drop_first=True)
X = df.drop(['target_variable_name'], axis=1)
y = df['target_variable_name']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = MinMaxScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)


model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# logistic reg
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

accuracy = accuracy_score(y_test, y_pred)
confusion_matrix(y_test,y_pred)
print(classification_report(y_test, y_pred))

df.select_dtypes(include=['number'])

# Plot box and whiskers plot
plt.figure(figsize=(8, 6))
plt.boxplot(data['LeadTime'])
plt.title('Box and Whiskers Plot')
plt.xlabel('LeadTime')
plt.ylabel('Values')
plt.show()

# Calculate the first and third quartiles (Q1 and Q3)
Q1 = data['LeadTime'].quantile(0.25)
Q3 = data['LeadTime'].quantile(0.75)

# Calculate the interquartile range (IQR)
IQR = Q3 - Q1

# Define the lower and upper bounds to identify outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Remove outliers
df = data[(data['LeadTime'] >= lower_bound) & (data['LeadTime'] <= upper_bound)]