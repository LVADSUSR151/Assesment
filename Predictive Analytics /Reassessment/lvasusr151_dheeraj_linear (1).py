# -*- coding: utf-8 -*-
"""Lvasusr151_Dheeraj_Linear.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IU4bRtTM1YgjMn0zs_oGW8qoblTaXbFC

**Problem Statement**
Benguluru House Price Prediction
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
import math

url = 'https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/bengaluru_house_prices.csv'
df = pd.read_csv(url)

"""# Basic Analysis"""

df.shape

df.head()

df.describe()

df.info()

"""### Handleling Missing Values"""

df.isnull().sum()

# droping all the null values

df = df.dropna()

df.isnull().sum()

"""**Handeling Duplicates**"""

# Cheking for Duplicates
df.duplicated().sum()

# printing Duplicates
duplicated_rows = df[df.duplicated(keep=False)]
print(duplicated_rows)

# droping Duplicates rows
df = df.drop_duplicates()

df.duplicated().sum()

# now there is no duplicates

"""### Outlier Detection & Handle It"""

for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

"""as there are few outliers in the bath column and price column so removing all the outliers

"""

# removing Outliers
for i in df.select_dtypes(include=['int64','float64']).columns:
  q1 = df[i].quantile(0.25)
  q3 = df[i].quantile(0.75)
  iqr = q3-q1
  lwr = q1-1.5*iqr
  upr = q3+1.5*iqr
  df.loc[df[i]>upr,i]=upr
  df.loc[df[i]<lwr,i]=lwr

for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

"""
## Univariate Analysis"""

for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

"""# findings

- The distribution of 'bath' is right skewed.
- The distribution of 'balcony' is left skewed.
- The distribution of 'price' is right skewed.
- The distribution of 'area' is right skewed.
- The distribution of 'sqft' is right skewed.
"""

# Plot bar charts for categorical columns
for column in df.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(10, 5))
    df[column].value_counts().plot(kind='bar')
    plt.title(f'Bar Chart of {column}')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.show()

"""# findings from above bar plots

1. **Location:** The 'location' bar chart shows that 'Electronic City' has the highest number of houses, followed by 'Whitefield' and 'Sarjapur Road'.
2. **Size:** The 'size' bar chart indicates that 2 BHK apartments are the most common, followed by 3 BHK and 1 BHK apartments.
3. **BHK:** The 'bhk' bar chart reveals that 2 BHK apartments are the most popular, followed by 3 BHK and 1 BHK apartments.

## Bi-Variate Analysis
"""

# Corelation between numeric columns
df.corr(numeric_only=True)

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(df.select_dtypes(include=['float64', 'int64']).corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

# Generate scatter plots for pairs of numerical variables
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

"""## Feature Engineering"""

df.head(4)

# dropping the availability and society as it wont be required for the model
df.drop(columns=['availability','society'],inplace=True)

df['area_type'].value_counts()

df['area_type'].value_counts().plot(kind='bar')
plt.title('Bar Chart of Area Type')
plt.xlabel('Area Type')
plt.ylabel('Count')
plt.show()

df.head()

# categorical into numerical columns
label_encoder = LabelEncoder()
df['area_type'] = label_encoder.fit_transform(df['area_type'])
df['location'] = label_encoder.fit_transform(df['location'])
df['size'] = label_encoder.fit_transform(df['size'])

df.head()

# df = pd.get_dummies(df, columns=['Gear'],dtype=int)
# df["Car Brand"]=df.groupby("Car Brand")["Price"].transform("mean")
# df["Model"]=df.groupby("Model")["Price"].transform("mean")

"""### Feature Scaling"""

df.columns

X = df.drop(columns = ["price",'total_sqft'])
y = df["price"]

X.info()

from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X, y)
feature_importances = rf.feature_importances_
sorted_indices = np.argsort(feature_importances)
feature_names = X.columns
sorted_importances = feature_importances[sorted_indices]
sorted_feature_names = feature_names[sorted_indices]
plt.barh(sorted_feature_names, sorted_importances, color='skyblue')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.title('Feature Importance')

"""# from above graph

- The most important feature for predicting the price of a house in Bengaluru is the location, followed by the size of the house and the bath.
- The least important features are the area type and the balcony.
- This information can be used to prioritize which features to focus on when collecting data or building a model to predict house prices.
"""

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)

X_train.shape

y_train.shape

# Scaling the data
scaler = MinMaxScaler()
X_train=pd.DataFrame(scaler.fit_transform(X_train[list(X.columns)]),
                                    columns=X.columns)
X_test=pd.DataFrame(scaler.transform(X_test[list(X.columns)]),
                                    columns=X.columns)

X_train.head()

"""## Model Implementation"""

# Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# predicted value sample
y_pred[:5]

"""# Model Evaluation"""

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print("Mean Squared Error:", mse)

rmse = mean_squared_error(y_test, y_pred,squared=False)
print("Root Mean Squared Error:", rmse)

# Coefficients and intercept
print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)

r2_s = r2_score(y_test, y_pred)
print("R2 Score:", r2_s)

"""#business Recommendation

1. **Location is the most important factor in determining the price of a house in Bengaluru.** This insight can be used by real estate developers to focus on developing properties in desirable locations.
2. **The size of the house and the number of bedrooms are also important factors in determining the price.** This insight can be used by buyers to narrow down their search to houses that meet their needs and budget.
3. **The area type and the balcony are the least important factors in determining the price.** This insight can be used by sellers to focus on highlighting the more important features of their property when marketing it for sale.
4. **The average price of a house in Bengaluru is â‚¹1.07 crores.** This insight can be used by buyers to get a general idea of what they can expect to pay for a house in the city.
5. **The R2 score for the linear regression model is 0.79.** This insight indicates that the model is able to explain 79% of the variation in the price of houses in Bengaluru.** This insight can be used by buyers and sellers to make more informed decisions about buying or selling a house in the city.
"""